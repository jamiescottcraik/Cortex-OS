version: '3.8'

services:
  # Reverse Proxy with SSL termination
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ../infra/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ../infra/nginx/ssl:/etc/nginx/ssl:ro
      - nginx_logs:/var/log/nginx
    environment:
      - NGINX_ENVSUBST_TEMPLATE_DIR=/etc/nginx/templates
      - NGINX_ENVSUBST_OUTPUT_DIR=/etc/nginx/conf.d
    depends_on:
      - cortex-api
      - cortex-web
    networks:
      - cortex-network
      - external
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "nginx", "-t"]
      interval: 30s
      timeout: 10s
      retries: 3

  # FastAPI Backend
  cortex-api:
    build:
      context: ..
      dockerfile: apps/cortex-py/Dockerfile.prod
      args:
        - BUILD_ENV=production
    environment:
      - ENVIRONMENT=production
      - LOG_LEVEL=info
      - BACKEND_CORS_ORIGINS=["https://cortex.example.com"]
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD_FILE=/run/secrets/neo4j_password
      - JAEGER_ENDPOINT=http://jaeger:4318
      - OPENTELEMETRY_ENABLED=true
      - RATE_LIMIT_ENABLED=true
      - SECURITY_HEADERS_ENABLED=true
    volumes:
      - api_logs:/app/logs
      - ../data:/app/data:ro
    depends_on:
      qdrant:
        condition: service_healthy
      neo4j:
        condition: service_healthy
      jaeger:
        condition: service_started
    networks:
      - cortex-network
    restart: unless-stopped
    secrets:
      - neo4j_password
      - openai_api_key
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'

  # Next.js Frontend
  cortex-web:
    build:
      context: ..
      dockerfile: apps/cortex-web/Dockerfile.prod
      args:
        - BUILD_ENV=production
        - NEXT_PUBLIC_API_URL=https://api.cortex.example.com
    environment:
      - NODE_ENV=production
      - NEXT_PUBLIC_API_URL=https://api.cortex.example.com
      - INTERNAL_API_URL=http://cortex-api:8000
      - NEXT_TELEMETRY_DISABLED=1
    depends_on:
      - cortex-api
    networks:
      - cortex-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
          cpus: '0.25'

  # Python Agent Orchestrator
  cortex-agents:
    build:
      context: ./packages/orchestration
      dockerfile: Dockerfile.prod
    environment:
      - ENVIRONMENT=production
      - LOG_LEVEL=info
      - LANGCHAIN_ENDPOINT=http://cortex-api:8000
      - CREWAI_ENDPOINT=http://cortex-api:8000
      - AUTOGEN_ENDPOINT=http://cortex-api:8000
      - JAEGER_ENDPOINT=http://jaeger:4318
      - OPENTELEMETRY_ENABLED=true
    volumes:
      - agent_logs:/app/logs
      - agent_data:/app/data
    depends_on:
      - cortex-api
      - qdrant
      - neo4j
    networks:
      - cortex-network
    restart: unless-stopped
    secrets:
      - openai_api_key
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8001/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'

  # Vector Database - Qdrant
  qdrant:
    image: qdrant/qdrant:v1.7.4
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_data:/qdrant/storage
      - ./infra/qdrant/config.yaml:/qdrant/config/production.yaml
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__SERVICE__GRPC_PORT=6334
      - QDRANT__CLUSTER__ENABLED=false
      - QDRANT__STORAGE__PERFORMANCE__MAX_SEGMENT_SIZE=2000000
    networks:
      - cortex-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'

  # Graph Database - Neo4j
  neo4j:
    image: neo4j:5.15-community
    ports:
      - "7474:7474"
      - "7687:7687"
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
      - neo4j_conf:/conf
      - ./infra/neo4j/neo4j.conf:/conf/neo4j.conf
    environment:
      - NEO4J_AUTH=neo4j/cortexproduction
      - NEO4J_PLUGINS=["apoc", "apoc-extended"]
      - NEO4J_dbms_security_procedures_unrestricted=apoc.*
      - NEO4J_dbms_memory_heap_initial__size=1G
      - NEO4J_dbms_memory_heap_max__size=2G
      - NEO4J_dbms_memory_pagecache_size=1G
    networks:
      - cortex-network
    restart: unless-stopped
    secrets:
      - neo4j_password
    healthcheck:
      test: ["CMD", "cypher-shell", "-u", "neo4j", "-p", "cortexproduction", "RETURN 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'

  # Distributed Tracing - Jaeger
  jaeger:
    image: jaegertracing/all-in-one:1.53
    ports:
      - "16686:16686"
      - "4317:4317"
      - "4318:4318"
    environment:
      - COLLECTOR_OTLP_ENABLED=true
      - SPAN_STORAGE_TYPE=elasticsearch
      - ES_SERVER_URLS=http://elasticsearch:9200
      - ES_USERNAME=elastic
      - ES_PASSWORD_FILE=/run/secrets/elasticsearch_password
    volumes:
      - jaeger_data:/tmp
    depends_on:
      - elasticsearch
    networks:
      - cortex-network
    restart: unless-stopped
    secrets:
      - elasticsearch_password
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:16686/"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Metrics Collection - Prometheus
  prometheus:
    image: prom/prometheus:v2.48.1
    ports:
      - "9090:9090"
    volumes:
      - ./infra/prometheus/prometheus.prod.yml:/etc/prometheus/prometheus.yml:ro
      - ./infra/prometheus/rules:/etc/prometheus/rules:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
      - '--storage.tsdb.min-block-duration=2h'
      - '--storage.tsdb.max-block-duration=2h'
    networks:
      - cortex-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'

  # Dashboard Visualization - Grafana
  grafana:
    image: grafana/grafana:10.2.3
    ports:
      - "3001:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./infra/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./infra/grafana/datasources:/etc/grafana/provisioning/datasources:ro
      - ./infra/grafana/grafana.ini:/etc/grafana/grafana.ini:ro
    environment:
      - GF_SECURITY_ADMIN_PASSWORD_FILE=/run/secrets/grafana_admin_password
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SERVER_DOMAIN=grafana.cortex.example.com
      - GF_SERVER_ROOT_URL=https://grafana.cortex.example.com
      - GF_SECURITY_COOKIE_SECURE=true
      - GF_SECURITY_COOKIE_SAMESITE=strict
      - GF_LOG_LEVEL=warn
    networks:
      - cortex-network
    restart: unless-stopped
    depends_on:
      - prometheus
    secrets:
      - grafana_admin_password
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Log Aggregation - Elasticsearch
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.3
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms2g -Xmx2g
      - xpack.security.enabled=true
      - ELASTIC_PASSWORD_FILE=/run/secrets/elasticsearch_password
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
      - ./infra/elasticsearch/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro
    networks:
      - cortex-network
    restart: unless-stopped
    secrets:
      - elasticsearch_password
    healthcheck:
      test: ["CMD", "curl", "-f", "-u", "elastic:$(cat /run/secrets/elasticsearch_password)", "http://localhost:9200/_cluster/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'

  # Log Processing - Logstash
  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.3
    volumes:
      - ./infra/logstash/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
      - ./infra/logstash/pipeline:/usr/share/logstash/pipeline:ro
      - api_logs:/logs/api:ro
      - agent_logs:/logs/agents:ro
      - nginx_logs:/logs/nginx:ro
    environment:
      - LS_JAVA_OPTS=-Xms1g -Xmx1g
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      - elasticsearch
    networks:
      - cortex-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'

  # Local AI - Ollama
  ollama:
    image: ollama/ollama:0.1.17
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
      - ./infra/ollama/models:/models
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_KEEP_ALIVE=24h
      - OLLAMA_MAX_LOADED_MODELS=3
    networks:
      - cortex-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/version"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4.0'
        reservations:
          memory: 4G
          cpus: '2.0'

  # Backup Service
  backup:
    image: alpine:3.19
    volumes:
      - qdrant_data:/backup/qdrant:ro
      - neo4j_data:/backup/neo4j:ro
      - grafana_data:/backup/grafana:ro
      - prometheus_data:/backup/prometheus:ro
      - ./scripts/backup:/scripts:ro
      - backup_storage:/backup/storage
    command: /scripts/backup-cron.sh
    networks:
      - cortex-network
    restart: unless-stopped
    environment:
      - BACKUP_RETENTION_DAYS=30
      - BACKUP_SCHEDULE=0 2 * * *
    depends_on:
      - qdrant
      - neo4j
      - prometheus
      - grafana

volumes:
  qdrant_data:
    driver: local
  neo4j_data:
    driver: local
  neo4j_logs:
    driver: local
  neo4j_conf:
    driver: local
  ollama_data:
    driver: local
  api_logs:
    driver: local
  agent_logs:
    driver: local
  agent_data:
    driver: local
  nginx_logs:
    driver: local
  jaeger_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  elasticsearch_data:
    driver: local
  backup_storage:
    driver: local

networks:
  cortex-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
  external:
    driver: bridge

secrets:
  neo4j_password:
    file: ../secrets/neo4j_password.txt
  openai_api_key:
    file: ../secrets/openai_api_key.txt
  grafana_admin_password:
    file: ../secrets/grafana_admin_password.txt
  elasticsearch_password:
    file: ../secrets/elasticsearch_password.txt

# © 2025 brAInwav LLC — every line reduces barriers, enhances security, and supports resilient AI engineering.
