{
	"coding_models_mlx": [
		{
			"name": "GLM-4.5-mlx-4Bit",
			"repo": "brAInwav/GLM-4.5-mlx-4Bit",
			"ram_gb": 8.0,
			"path": "/Volumes/ExternalSSD/ai-cache/huggingface/hub/models--brAInwav--GLM-4.5-mlx-4Bit",
			"size_bytes": null,
			"priority": 1,
			"description": "High-quality general model with excellent coding capabilities",
			"coding_tasks": ["general", "refactoring", "debugging", "documentation"],
			"context_length": 32768
		},
		{
			"name": "qwen3-coder-7b-mlx",
			"repo": "mlx-community/qwen3-coder-7b-mlx",
			"ram_gb": 8.0,
			"path": "/Volumes/ExternalSSD/ai-models/local-models/qwen3-coder-7b-mlx",
			"size_bytes": null,
			"priority": 2,
			"description": "Specialized coding model optimized for code generation",
			"coding_tasks": ["code_generation", "completion", "simple_fixes"],
			"context_length": 16384
		},
		{
			"name": "Qwen3-Coder-30B-A3B-Instruct-4bit",
			"repo": "mlx-community/Qwen3-Coder-30B-A3B-Instruct-4bit",
			"ram_gb": 17.0,
			"path": "/Volumes/ExternalSSD/ai-models/local-models/Qwen3-Coder-30B-A3B-Instruct-4bit",
			"size_bytes": null,
			"priority": 3,
			"description": "Large coding model for complex architectural tasks",
			"coding_tasks": ["architecture", "complex_refactoring", "large_codebase"],
			"context_length": 32768
		},
		{
			"name": "gpt-oss-20b-8bit-mlx",
			"repo": null,
			"ram_gb": 24.0,
			"path": "/Volumes/ExternalSSD/ai-models/local-models/gpt-oss-20b-8bit-mlx",
			"size_bytes": null,
			"priority": 4,
			"description": "High-quality open source GPT model for advanced coding tasks",
			"coding_tasks": [
				"advanced_algorithms",
				"system_design",
				"performance_optimization"
			],
			"context_length": 8192
		}
	],
	"coding_models_ollama": [
		{
			"name": "deepseek-coder:6.7b",
			"tag": "6.7b",
			"ram_gb": 8.0,
			"priority": 1,
			"description": "Specialized coding model for code generation and completion",
			"coding_tasks": [
				"code_generation",
				"completion",
				"debugging",
				"refactoring"
			],
			"context_length": 16384
		},
		{
			"name": "qwen3-coder:30b",
			"tag": "30b",
			"ram_gb": 18.0,
			"priority": 2,
			"description": "Large coding model for complex architectural tasks",
			"coding_tasks": ["architecture", "complex_refactoring", "system_design"],
			"context_length": 32768
		},
		{
			"name": "gpt-oss:20b",
			"tag": "20b",
			"ram_gb": 15.0,
			"priority": 3,
			"description": "High-quality open source GPT model for advanced coding",
			"coding_tasks": [
				"advanced_algorithms",
				"performance_optimization",
				"documentation"
			],
			"context_length": 8192
		},
		{
			"name": "phi4-mini-reasoning:latest",
			"tag": "latest",
			"ram_gb": 4.0,
			"priority": 4,
			"description": "Fast reasoning model for quick coding tasks",
			"coding_tasks": ["quick_fixes", "simple_generation", "code_review"],
			"context_length": 4096
		}
	],
	"task_model_mapping": {
		"quick_fix": "qwen3-coder-7b-mlx",
		"code_generation": "qwen3-coder-7b-mlx",
		"refactoring": "GLM-4.5-mlx-4Bit",
		"debugging": "GLM-4.5-mlx-4Bit",
		"documentation": "GLM-4.5-mlx-4Bit",
		"architecture": "Qwen3-Coder-30B-A3B-Instruct-4bit",
		"complex_analysis": "Qwen3-Coder-30B-A3B-Instruct-4bit",
		"performance_optimization": "gpt-oss-20b-8bit-mlx",
		"system_design": "gpt-oss-20b-8bit-mlx",
		"default": "GLM-4.5-mlx-4Bit",
		"ollama_fallback": {
			"quick_fix": "deepseek-coder:6.7b",
			"code_generation": "deepseek-coder:6.7b",
			"refactoring": "deepseek-coder:6.7b",
			"debugging": "deepseek-coder:6.7b",
			"architecture": "qwen3-coder:30b",
			"complex_analysis": "qwen3-coder:30b",
			"performance_optimization": "gpt-oss:20b",
			"system_design": "gpt-oss:20b",
			"default": "deepseek-coder:6.7b"
		}
	}
}
