{
	"mlx": [
		{
			"name": "qwen3-embedding-0.6b-mlx",
			"repo": "mlx-community/qwen3-embedding-0.6b-mlx",
			"ram_gb": 1.0,
			"path": "/Volumes/ExternalSSD/ai-models/local-models/qwen3-embedding-0.6b-mlx",
			"size_bytes": null
		},
		{
			"name": "qwen3-embedding-4b-mlx",
			"repo": "mlx-community/qwen3-embedding-4b-mlx",
			"ram_gb": 3.5,
			"path": "/Volumes/ExternalSSD/ai-models/local-models/qwen3-embedding-4b-mlx",
			"size_bytes": null
		},
		{
			"name": "qwen3-embedding-8b-mlx",
			"repo": "mlx-community/qwen3-embedding-8b-mlx",
			"ram_gb": 7.0,
			"path": "/Volumes/ExternalSSD/ai-models/local-models/qwen3-embedding-8b-mlx",
			"size_bytes": null
		},
		{
			"name": "gemma2-emb-15b-moe",
			"repo": null,
			"ram_gb": 12.0,
			"path": "/Volumes/ExternalSSD/ai-models/local-models/gemma2-emb-15b-moe",
			"size_bytes": null
		},
		{
			"name": "qwen3-reranker-4b-mlx",
			"repo": "mlx-community/qwen3-reranker-4b-mlx",
			"ram_gb": 4.0,
			"path": "/Volumes/ExternalSSD/ai-models/local-models/qwen3-reranker-4b-mlx",
			"size_bytes": null
		},
		{
			"name": "qwen3-coder-7b-mlx",
			"repo": "mlx-community/qwen3-coder-7b-mlx",
			"ram_gb": 8.0,
			"path": "/Volumes/ExternalSSD/ai-models/local-models/qwen3-coder-7b-mlx",
			"size_bytes": null
		},
		{
			"name": "llamaguard-2-14b-mlx",
			"repo": null,
			"ram_gb": 16.0,
			"path": "/Volumes/ExternalSSD/ai-models/local-models/llamaguard-2-14b-mlx",
			"size_bytes": null
		},
		{
			"name": "Qwen3-Coder-30B-A3B-Instruct-4bit",
			"repo": "mlx-community/Qwen3-Coder-30B-A3B-Instruct-4bit",
			"ram_gb": 17.0,
			"path": "/Volumes/ExternalSSD/ai-models/local-models/Qwen3-Coder-30B-A3B-Instruct-4bit",
			"size_bytes": null
		},
		{
			"name": "Qwen3-30B-A3B-Instruct-4bit",
			"repo": "mlx-community/Qwen3-30B-A3B-Instruct-4bit",
			"ram_gb": 22.0,
			"path": "/Volumes/ExternalSSD/ai-models/local-models/Qwen3-30B-A3B-Instruct-4bit",
			"size_bytes": null
		},
		{
			"name": "Mixtral-8x7B-v0.1-hf-4bit-mlx",
			"repo": "mlx-community/Mixtral-8x7B-v0.1-hf-4bit-mlx",
			"ram_gb": 12.0,
			"path": "/Volumes/ExternalSSD/ai-models/local-models/Mixtral-8x7B-v0.1-hf-4bit-mlx",
			"size_bytes": null
		},
		{
			"name": "Qwen2.5-VL-3B-Instruct-6bit",
			"repo": "mlx-community/Qwen2.5-VL-3B-Instruct-6bit",
			"ram_gb": 3.0,
			"path": "/Volumes/ExternalSSD/ai-models/local-models/Qwen2.5-VL-3B-Instruct-6bit",
			"size_bytes": null
		},
		{
			"name": "Qwen2.5-7B-Instruct-4bit-mlx",
			"repo": "mlx-community/Qwen2.5-7B-Instruct-4bit-mlx",
			"ram_gb": 7.0,
			"path": "/Volumes/ExternalSSD/ai-models/local-models/Qwen2.5-7B-Instruct-4bit-mlx",
			"size_bytes": null
		},
		{
			"name": "Phi-3-mini-4k-instruct-4bit",
			"repo": "mlx-community/Phi-3-mini-4k-instruct-4bit",
			"ram_gb": 2.0,
			"path": "/Volumes/ExternalSSD/ai-models/local-models/Phi-3-mini-4k-instruct-4bit",
			"size_bytes": null
		},
		{
			"name": "gpt-oss-20b-8bit-mlx",
			"repo": null,
			"ram_gb": 24.0,
			"path": "/Volumes/ExternalSSD/ai-models/local-models/gpt-oss-20b-8bit-mlx",
			"size_bytes": null
		}
	],
	"ollama": [
		{
			"name": "deepseek-coder",
			"tag": "6.7b",
			"manifest_path": "/Volumes/ExternalSSD/ai-models/ollama/models/manifests/registry.ollama.ai/library/deepseek-coder/6.7b",
			"note": "manifest shows model layers and sizes"
		},
		{
			"name": "gemma3n",
			"tag": "e4b",
			"manifest_path": "/Volumes/ExternalSSD/ai-models/ollama/models/manifests/registry.ollama.ai/library/gemma3n/e4b"
		},
		{
			"name": "gpt-oss",
			"tag": "20b",
			"manifest_path": "/Volumes/ExternalSSD/ai-models/ollama/models/manifests/registry.ollama.ai/library/gpt-oss/20b",
			"size_bytes": 13780154624
		},
		{
			"name": "granite-embedding",
			"tag": "278m",
			"manifest_path": "/Volumes/ExternalSSD/ai-models/ollama/models/manifests/registry.ollama.ai/library/granite-embedding/278m",
			"size_bytes": 562765632
		},
		{
			"name": "nomic-embed-text",
			"tag": "v1.5",
			"manifest_path": "/Volumes/ExternalSSD/ai-models/ollama/models/manifests/registry.ollama.ai/library/nomic-embed-text/v1.5",
			"size_bytes": 274290656
		},
		{
			"name": "phi4-mini-reasoning",
			"tag": "latest",
			"manifest_path": "/Volumes/ExternalSSD/ai-models/ollama/models/manifests/registry.ollama.ai/library/phi4-mini-reasoning/latest",
			"size_bytes": 3152477440
		},
		{
			"name": "qwen3-coder",
			"tag": "30b",
			"manifest_path": "/Volumes/ExternalSSD/ai-models/ollama/models/manifests/registry.ollama.ai/library/qwen3-coder/30b",
			"size_bytes": 18556688736
		}
	],
	"huggingface_legacy": [
		{
			"dir": "/Volumes/ExternalSSD/ai-cache/huggingface/hub/models--lmstudio-community--gpt-oss-20b-MLX-8bit",
			"name": "models--lmstudio-community--gpt-oss-20b-MLX-8bit"
		},
		{
			"dir": "/Volumes/ExternalSSD/ai-cache/huggingface/hub/models--brAInwav--GLM-4.5-mlx-4Bit",
			"name": "models--brAInwav--GLM-4.5-mlx-4Bit"
		},
		{
			"dir": "/Volumes/ExternalSSD/ai-cache/huggingface/hub/models--mlx-community--SmolLM-135M-Instruct-4bit",
			"name": "models--mlx-community--SmolLM-135M-Instruct-4bit"
		},
		{
			"dir": "/Volumes/ExternalSSD/ai-cache/huggingface/hub/models--Qwen--Qwen3-Embedding-4B",
			"name": "models--Qwen--Qwen3-Embedding-4B"
		}
	],
	"mlx_knife": [
		{
			"name": "SmolLM-135M-Instruct-4bit",
			"id": "642e06af",
			"size": "82.6 MB",
			"modified": "1 days ago"
		}
	]
}
