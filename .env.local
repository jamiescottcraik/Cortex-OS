# MLX/ExternalSSD Configuration - brAInwav Development Setup
# Auto-loaded by dev scripts to find models at ExternalSSD
# Optimized for fast local inference on Apple Silicon

# ===== Nx Cloud Configuration =====
# Get your access token from: https://cloud.nx.app/connect/bfBdWquyIm
NX_CLOUD_ACCESS_TOKEN=
NX_CLOUD_DISTRIBUTED_TASK_EXECUTION=true
NX_CLOUD_CACHE=true

# Hugging Face cache directory (speeds up downloads)
HF_HOME=/Volumes/ExternalSSD/huggingface_cache

# MLX cache directory (weights, compiled artifacts)
MLX_CACHE_DIR=/Volumes/ExternalSSD/ai-cache

# MLX models root - where mlx-knife finds local models
MLX_MODEL_PATH=/Volumes/ExternalSSD/ai-models

# Embeddings server base URL (for services/py-mlx-server)
MLX_EMBED_BASE_URL=http://127.0.0.1:8000

# Use MLX as the embedder in demos/tools that respect this flag
MEMORIES_EMBEDDER=mlx

# Additional environment variables for MLX/ExternalSSD integration
TRANSFORMERS_CACHE=/Volumes/ExternalSSD/ai-cache/huggingface/transformers

# Performance tuning for ExternalSSD
MLX_MEMORY_FRACTION=0.8
MLX_CACHE_ENABLED=true

# Optional performance knobs
# MAX_VITEST_PROCESSES_SAFE=2
# VITEST_ALLOW_CONCURRENT=false
