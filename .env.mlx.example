# MLX environment configuration template (macOS / External SSD)
# Copy to `.env.local` or export in your shell profile
# Paths below assume your models and caches live on an external volume

# Hugging Face cache directory (speeds up downloads)
HF_HOME=/Volumes/ExternalSSD/huggingface_cache

# MLX cache directory (weights, compiled artifacts)
MLX_CACHE_DIR=/Volumes/ExternalSSD/ai-cache

# Optional: default MLX models root (if your tools expect a base path)
# e.g., where mlx-knife or your own adapters find local models
MLX_MODEL_PATH=/Volumes/ExternalSSD/ai-models

# Embeddings server base URL (for services/py-mlx-server)
MLX_EMBED_BASE_URL=http://127.0.0.1:8000

# Use MLX as the embedder in demos/tools that respect this flag
MEMORIES_EMBEDDER=mlx

# Optional performance knobs
# MAX_VITEST_PROCESSES_SAFE=2
# VITEST_ALLOW_CONCURRENT=false
