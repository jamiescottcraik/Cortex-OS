rules:
  - id: llm-prompt-injection
    message: 'Unsanitized user input concatenated into LLM prompt'
    metadata:
      owasp-llm-top-10: LLM01-Prompt-Injection
      mitre-atlas: ATLAS-Prompt-Injection
      agentic-security: prompt-injection
      personal-security-checklist: secure-coding
      aliasrobotics-cai: LLM-Prompt-Injection
    severity: WARNING
    languages: [javascript, typescript]
    patterns:
      - pattern: $LLM($PROMPT + $USER_INPUT)
      - pattern: $LLM(`$PROMPT${$USER_INPUT}`)
      - pattern: $LLM([$PROMPT, $USER_INPUT].join(''))
      - pattern: $LLM($PROMPT.concat($USER_INPUT))
      - metavariable-regex:
          regex: (?i)(input|prompt|user|query|data|content|message|text|param)

  - id: llm-eval-on-output
    message: 'Avoid eval on potential LLM output'
    metadata:
      owasp-llm-top-10: LLM02-Insecure-Output
      mitre-atlas: ATLAS-Insecure-Output
      agentic-security: insecure-output
      personal-security-checklist: secure-coding
      aliasrobotics-cai: LLM-Insecure-Output
    severity: ERROR
    languages: [javascript, typescript]
    patterns:
      - pattern: eval($OUTPUT)
      - metavariable-pattern:
          metavariable: $OUTPUT
          pattern: $LLM(...)
