{
  "embedding_models": {
    "qwen3-0.6b": {
      "name": "Qwen3-Embedding-0.6B",
      "path": "${MLX_CACHE_DIR}/models--Qwen--Qwen3-Embedding-0.6B",
      "dimensions": 768,
      "max_tokens": 8192,
      "recommended_for": [
        "quick_search",
        "development"
      ],
      "transformers_model": "Qwen/Qwen3-Embedding-0.6B",
      "memory_gb": 1.0
    },
    "qwen3-4b": {
      "name": "Qwen3-Embedding-4B",
      "path": "${MLX_CACHE_DIR}/models--Qwen--Qwen3-Embedding-4B",
      "dimensions": 768,
      "max_tokens": 8192,
      "recommended_for": [
        "production",
        "balanced_performance"
      ],
      "transformers_model": "Qwen/Qwen3-Embedding-4B",
      "memory_gb": 4.0
    },
    "qwen3-8b": {
      "name": "Qwen3-Embedding-8B",
      "path": "${MLX_CACHE_DIR}/models--Qwen--Qwen3-Embedding-8B",
      "dimensions": 768,
      "max_tokens": 8192,
      "recommended_for": [
        "high_accuracy",
        "research"
      ],
      "transformers_model": "Qwen/Qwen3-Embedding-8B",
      "memory_gb": 8.0
    }
  },
  "reranker_models": {
    "qwen3-reranker": {
      "name": "Qwen3-Reranker-4B",
      "path": "${MLX_CACHE_DIR}/models--Qwen--Qwen3-Reranker-4B",
      "transformers_model": "Qwen/Qwen3-Reranker-4B",
      "max_pairs": 1000,
      "memory_gb": 4.0,
      "recommended_for": [
        "production_reranking",
        "search_optimization"
      ]
    }
  },
  "chat_models": {
    "glm-4.5": {
      "name": "GLM-4.5-mlx-4Bit",
      "path": "/Volumes/ExternalSSD/ai-cache/huggingface/hub/models--brAInwav--GLM-4.5-mlx-4Bit",
      "transformers_model": "brAInwav/GLM-4.5-mlx-4Bit",
      "quantization": "4bit",
      "context_length": 32768,
      "memory_gb": 8.0,
      "priority": 1,
      "recommended_for": [
        "coding",
        "refactoring",
        "debugging",
        "documentation",
        "general_purpose"
      ],
      "coding_tasks": [
        "general",
        "refactoring",
        "debugging",
        "documentation"
      ]
    },
    "llama-3.1-8b": {
      "name": "Llama-3.1-8B-Instruct",
      "path": "/Volumes/ExternalSSD/ai-cache/huggingface/hub/models--mlx-community--Llama-3.1-8B-Instruct",
      "transformers_model": "mlx-community/Llama-3.1-8B-Instruct",
      "quantization": "native",
      "context_length": 32768,
      "memory_gb": 12.0,
      "priority": 2,
      "recommended_for": [
        "general_purpose",
        "instruction_following",
        "reasoning"
      ],
      "coding_tasks": [
        "general",
        "code_review",
        "explanation"
      ]
    },
    "gpt-oss-20b": {
      "name": "gpt-oss-20b-8bit-mlx",
      "path": "/Volumes/ExternalSSD/ai-cache/huggingface/hub/models--lmstudio-community--gpt-oss-20b-MLX-8bit",
      "transformers_model": "lmstudio-community/gpt-oss-20b-MLX-8bit",
      "quantization": "8bit",
      "context_length": 8192,
      "memory_gb": 24.0,
      "priority": 4,
      "recommended_for": [
        "advanced_algorithms",
        "system_design",
        "performance_optimization"
      ],
      "coding_tasks": [
        "advanced_algorithms",
        "system_design",
        "performance_optimization"
      ]
    },
    "qwen2.5-0.5b": {
      "name": "mlx-community/Qwen2.5-0.5B-Instruct-4bit",
      "path": "${MLX_CACHE_DIR}/hub/models--mlx-community--Qwen2.5-0.5B-Instruct-4bit",
      "transformers_model": "mlx-community/Qwen2.5-0.5B-Instruct-4bit",
      "quantization": "4bit",
      "context_length": 32768,
      "memory_gb": 1.0,
      "recommended_for": [
        "fast_inference",
        "development",
        "testing"
      ],
      "coding_tasks": [
        "quick_fixes",
        "simple_generation"
      ]
    },
    "qwen2.5-vl": {
      "name": "mlx-community/Qwen2.5-VL-3B-Instruct-6bit",
      "path": "${MLX_CACHE_DIR}/hub/models--mlx-community--Qwen2.5-VL-3B-Instruct-6bit",
      "transformers_model": "mlx-community/Qwen2.5-VL-3B-Instruct-6bit",
      "quantization": "6bit",
      "supports_vision": true,
      "context_length": 32768,
      "memory_gb": 6.0,
      "recommended_for": [
        "multimodal",
        "vision_tasks",
        "image_analysis"
      ],
      "coding_tasks": [
        "ui_analysis",
        "diagram_interpretation",
        "visual_debugging"
      ]
    },
    "qwen3-coder-7b": {
      "name": "qwen3-coder-7b-mlx",
      "path": "/Volumes/ExternalSSD/ai-models/local-models/qwen3-coder-7b-mlx",
      "transformers_model": "mlx-community/qwen3-coder-7b-mlx",
      "quantization": "4bit",
      "context_length": 16384,
      "memory_gb": 8.0,
      "priority": 2,
      "recommended_for": [
        "code_generation",
        "completion",
        "simple_fixes"
      ],
      "coding_tasks": [
        "code_generation",
        "completion",
        "simple_fixes"
      ]
    },
    "qwen3-coder-30b": {
      "name": "mlx-community/Qwen3-Coder-30B-A3B-Instruct-4bit",
      "path": "${MLX_CACHE_DIR}/hub/models--mlx-community--Qwen3-Coder-30B-A3B-Instruct-4bit",
      "transformers_model": "mlx-community/Qwen3-Coder-30B-A3B-Instruct-4bit",
      "quantization": "4bit",
      "context_length": 32768,
      "memory_gb": 32.0,
      "priority": 3,
      "recommended_for": [
        "architecture",
        "complex_refactoring",
        "large_context",
        "system_design"
      ],
      "coding_tasks": [
        "architecture",
        "complex_refactoring",
        "large_codebase",
        "system_design"
      ]
    },
    "mixtral-8x7b": {
      "name": "mlx-community/Mixtral-8x7B-v0.1-hf-4bit-mlx",
      "path": "${MLX_CACHE_DIR}/hub/models--mlx-community--Mixtral-8x7B-v0.1-hf-4bit-mlx",
      "transformers_model": "mlx-community/Mixtral-8x7B-v0.1-hf-4bit-mlx",
      "quantization": "4bit",
      "type": "mixture_of_experts",
      "context_length": 32768,
      "memory_gb": 32.0,
      "recommended_for": [
        "complex_reasoning",
        "multilingual",
        "expert_domain_tasks"
      ],
      "coding_tasks": [
        "complex_reasoning",
        "multilingual_code",
        "domain_expertise"
      ]
    },
    "phi3-mini": {
      "name": "mlx-community/Phi-3-mini-4k-instruct-4bit",
      "path": "${MLX_CACHE_DIR}/hub/models--mlx-community--Phi-3-mini-4k-instruct-4bit",
      "transformers_model": "mlx-community/Phi-3-mini-4k-instruct-4bit",
      "quantization": "4bit",
      "context_length": 4096,
      "memory_gb": 4.0,
      "recommended_for": [
        "efficient_inference",
        "mobile",
        "quick_tasks"
      ],
      "coding_tasks": [
        "quick_fixes",
        "simple_generation",
        "code_review"
      ]
    },
    "gemma-2-2b": {
      "name": "mlx-community/gemma-2-2b-it-4bit",
      "path": "/Volumes/ExternalSSD/huggingface_cache/models--mlx-community--gemma-2-2b-it-4bit",
      "transformers_model": "mlx-community/gemma-2-2b-it-4bit",
      "quantization": "4bit",
      "context_length": 8192,
      "memory_gb": 4.0,
      "recommended_for": [
        "efficient_inference",
        "google_ecosystem",
        "balanced_performance"
      ],
      "coding_tasks": [
        "general",
        "code_review",
        "documentation"
      ]
    },
    "smol-lm-135m": {
      "name": "mlx-community/SmolLM-135M-Instruct-4bit",
      "path": "/Volumes/ExternalSSD/ai-cache/huggingface/hub/models--mlx-community--SmolLM-135M-Instruct-4bit",
      "transformers_model": "mlx-community/SmolLM-135M-Instruct-4bit",
      "quantization": "4bit",
      "context_length": 2048,
      "memory_gb": 1.0,
      "recommended_for": [
        "ultra_light",
        "testing",
        "edge_devices"
      ],
      "coding_tasks": [
        "simple_fixes",
        "basic_completion",
        "testing"
      ]
    },
    "gemma-3-270m": {
      "name": "google/gemma-3-270m-it",
      "path": "${MLX_CACHE_DIR}/models--google--gemma-3-270m-it",
      "transformers_model": "google/gemma-3-270m-it",
      "quantization": "4bit",
      "context_length": 8192,
      "memory_gb": 0.5,
      "tier": "always_on",
      "priority": 5,
      "recommended_for": [
        "ultra_fast",
        "quick_responses",
        "utility_tasks",
        "always_available"
      ],
      "coding_tasks": [
        "simple_fixes",
        "quick_completion",
        "utility_generation",
        "fast_responses"
      ]
    }
  },
  "safety_models": {
    "llama_guard": {
      "name": "llamas-community/LlamaGuard-7b",
      "path": "${MLX_CACHE_DIR}/models--llamas-community--LlamaGuard-7b",
      "transformers_model": "llamas-community/LlamaGuard-7b",
      "memory_gb": 7.0,
      "recommended_for": [
        "content_moderation",
        "safety_checks",
        "harmful_content_detection"
      ]
    }
  },
  "default_models": {
    "embedding": "qwen3-4b",
    "reranker": "qwen3-reranker",
    "chat": "glm-4.5",
    "coding": "glm-4.5",
    "vision": "qwen2.5-vl",
    "large_context": "qwen3-coder-30b",
    "lightweight": "qwen2.5-0.5b",
    "ultra_fast": "gemma-3-270m",
    "always_on": "gemma-3-270m",
    "safety": "llama_guard"
  },
  "task_routing": {
    "quick_fix": "qwen3-coder-7b",
    "code_generation": "qwen3-coder-7b",
    "refactoring": "glm-4.5",
    "debugging": "glm-4.5",
    "documentation": "glm-4.5",
    "architecture": "qwen3-coder-30b",
    "complex_analysis": "qwen3-coder-30b",
    "performance_optimization": "gpt-oss-20b",
    "system_design": "gpt-oss-20b",
    "vision_tasks": "qwen2.5-vl",
    "multilingual": "mixtral-8x7b",
    "lightweight_tasks": "phi3-mini",
    "utility_tasks": "gemma-3-270m",
    "fast_responses": "gemma-3-270m",
    "always_available": "gemma-3-270m",
    "default": "glm-4.5"
  }
}