# OrbStack-specific service additions for Cortex-OS (FIXED VERSION)
version: '3.8'

services:
  # Main cortex-code CLI service only (confirmed working binary)
  cortex-code-cli:
    container_name: cortexos_code_cli
    build:
      context: ../../
      dockerfile: apps/cortex-code/Dockerfile
      platforms:
        - linux/arm64
        - linux/amd64
    profiles: ["dev-full", "tools"]
    environment:
      RUST_LOG: debug
      CORTEX_CODE_CACHE_DIR: /app/cache  # FIX: Consistent naming
    volumes:
      - ../../:/workspace:ro
      - cortex_code_cache:/app/cache  # FIX: Consistent naming
    working_dir: /workspace
    mem_limit: "512m"
    labels:
      orbstack.optimize: "true"
      orbstack.service: "cortex-code-cli"
      orbstack.tier: "tools"
      orbstack.rosetta: "false"
    command: ["codex", "--help"]

  # Python ML services (kept as working)
  cortex-py-ml:
    container_name: cortexos_py_ml
    build:
      context: ../../
      dockerfile: apps/cortex-py/Dockerfile
      platforms:
        - linux/arm64
        - linux/amd64
    profiles: ["ml", "dev-full"]
    environment:
      PYTHONPATH: /app/src
      LOG_LEVEL: DEBUG
      TRANSFORMERS_CACHE: /app/cache/transformers
      HF_HOME: /app/cache/huggingface
    ports:
      - "8005:8000"
    volumes:
      - python_cache:/app/cache
      - model_cache:/app/models
      - huggingface_cache:/app/cache/huggingface
    mem_limit: "2g"
    labels:
      orbstack.optimize: "true"
      orbstack.service: "python-ml"
      orbstack.tier: "ai"
      orbstack.python: "true"
    command: ["python", "-m", "uvicorn", "src.main:app", "--host", "0.0.0.0", "--port", "8000"]

volumes:
  # FIX: Consistent naming scheme
  cortex_code_cache:
    driver: local
    labels:
      orbstack.volume: "cache"
      orbstack.service: "cortex-code"
  python_cache:
    driver: local
    labels:
      orbstack.volume: "cache"
      orbstack.service: "python"
  model_cache:
    driver: local
    labels:
      orbstack.volume: "models"
      orbstack.service: "ai"
  huggingface_cache:
    driver: local
    labels:
      orbstack.volume: "cache"
      orbstack.service: "huggingface"