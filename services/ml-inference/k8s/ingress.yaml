apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ml-inference-ingress
  namespace: cortex-os
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/rate-limit: "100"
spec:
  tls:
    - hosts:
        - ml-inference.cortex-os.local
      secretName: ml-inference-tls
  rules:
    - host: ml-inference.cortex-os.local
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: ml-inference-service
                port:
                  number: 8000
